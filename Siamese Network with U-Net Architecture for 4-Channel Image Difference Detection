# siamese_unet_4channel.py
"""
Siamese Network with U-Net Architecture for 4-Channel Image Difference Detection

This implementation processes 4-channel images (RGB + K-means green clustering map)
to detect differences, with emphasis on the fourth channel for plant invasion detection.
Supports multiple clustering methods (K-means, DBSCAN, GMM, AGG).

Author: Behrad
License: MIT
"""

import tensorflow as tf
from tensorflow.keras import layers, Model
import numpy as np
import matplotlib.pyplot as plt
import cv2
from scipy.ndimage import zoom
import random
import os
import argparse
from typing import Tuple, List
from dataclasses import dataclass

@dataclass
class Config:
    """Configuration class for model parameters."""
    patch_size: int = 200
    threshold: float = 0.06
    target_size: Tuple[int, int] = (6000, 6000)
    min_area: int = 30
    scale_factor: float = 0.5
    seed: int = 42
    memory_limit: int = 4096  # GPU memory limit in MB
    channel_weights: List[float] = None  # Weights for [R, G, B, K-means]

def set_seed(seed: int) -> None:
    """Set random seeds for reproducibility."""
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

def configure_gpu(config: Config) -> None:
    """Configure GPU memory growth."""
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.set_logical_device_configuration(
                    gpu,
                    [tf.config.LogicalDeviceConfiguration(memory_limit=config.memory_limit)]
                )
        except RuntimeError as e:
            print(f"GPU configuration error: {e}")

def se_block(input_tensor: tf.Tensor, reduction: int = 16) -> tf.Tensor:
    """Squeeze-and-Excitation block to emphasize important channels (e.g., K-means)."""
    channels = input_tensor.shape[-1]
    se = layers.GlobalAveragePooling2D()(input_tensor)
    se = layers.Dense(channels // reduction, activation='relu')(se)
    se = layers.Dense(channels, activation='sigmoid')(se)
    se = layers.Reshape((1, 1, channels))(se)
    return layers.Multiply()([input_tensor, se])

def crop_and_concat(upsampled: tf.Tensor, bypass: tf.Tensor) -> tf.Tensor:
    """Dynamically pad and concatenate upsampled and bypass layers."""
    def dynamic_padding(inputs):
        upsampled, bypass = inputs
        u_shape, b_shape = tf.shape(upsampled), tf.shape(bypass)
        diff_h = b_shape[1] - u_shape[1]
        diff_w = b_shape[2] - u_shape[2]
        pad_h1 = tf.maximum(diff_h // 2, 0)
        pad_h2 = tf.maximum(diff_h - diff_h // 2, 0)
        pad_w1 = tf.maximum(diff_w // 2, 0)
        pad_w2 = tf.maximum(diff_w - diff_w // 2, 0)
        return tf.pad(upsampled, [[0, 0], [pad_h1, pad_h2], [pad_w1, pad_w2], [0, 0]])
    
    return layers.concatenate([layers.Lambda(dynamic_padding)([upsampled, bypass]), bypass], axis=3)

def build_unet(input_shape: Tuple[int, int, int], channel_weights: List[float] = None) -> Model:
    """Build U-Net model with channel attention for 4-channel inputs."""
    inputs = layers.Input(shape=input_shape)
    
    # Apply channel weights if provided
    if channel_weights:
        weighted_inputs = layers.Lambda(lambda x: x * tf.constant(channel_weights, dtype=tf.float32))(inputs)
    else:
        weighted_inputs = inputs
    
    # Encoder with SE blocks
    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(weighted_inputs)
    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(c1)
    c1 = se_block(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)
    
    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(c2)
    c2 = se_block(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)
    
    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(c3)
    c3 = se_block(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)
    
    c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(c4)
    c4 = se_block(c4)
    p4 = layers.MaxPooling2D((2, 2))(c4)
    
    # Bottleneck
    c5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(p4)
    c5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(c5)
    c5 = se_block(c5)
    
    # Decoder
    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = crop_and_concat(u6, c4)
    c6 = layers.Conv2D(512, 3, activation='relu', padding='same')(u6)
    
    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = crop_and_concat(u7, c3)
    c7 = layers.Conv2D(256, 3, activation='relu', padding='same')(u7)
    
    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = crop_and_concat(u8, c2)
    c8 = layers.Conv2D(128, 3, activation='relu', padding='same')(u8)
    
    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = crop_and_concat(u9, c1)
    c9 = layers.Conv2D(64, 3, activation='relu', padding='same')(u9)
    
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c9)
    return Model(inputs, outputs)

def create_patches(image: np.ndarray, patch_size: int) -> np.ndarray:
    """Split image into patches."""
    h, w, _ = image.shape
    patches = [
        image[i:i+patch_size, j:j+patch_size]
        for i in range(0, h, patch_size)
        for j in range(0, w, patch_size)
        if image[i:i+patch_size, j:j+patch_size].shape[:2] == (patch_size, patch_size)
    ]
    return np.array(patches)

def generate_heatmap(diff_vector: np.ndarray, patch_size: int, threshold: float) -> np.ndarray:
    """Generate binary heatmap from difference vector."""
    heatmap = np.reshape(np.abs(diff_vector), (patch_size, patch_size))
    return np.where(heatmap > threshold, 1, 0)

def stitch_heatmaps(heatmaps: List[np.ndarray], image_shape: Tuple[int, int], patch_size: int) -> np.ndarray:
    """Stitch patch heatmaps into full image."""
    h, w = image_shape
    full_heatmap = np.zeros((h, w))
    idx = 0
    for i in range(0, h, patch_size):
        for j in range(0, w, patch_size):
            full_heatmap[i:i+patch_size, j:j+patch_size] = zoom(
                heatmaps[idx],
                (patch_size / heatmaps[idx].shape[0], patch_size / heatmaps[idx].shape[1]),
                order=3
            )
            idx += 1
    return full_heatmap

def apply_connected_components_filter(heatmap: np.ndarray, min_area: int) -> np.ndarray:
    """Filter heatmap using connected components."""
    heatmap_uint8 = (heatmap * 255).astype(np.uint8)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(heatmap_uint8, connectivity=8)
    filtered_heatmap = np.zeros_like(heatmap)
    for i in range(1, num_labels):
        if stats[i, cv2.CC_STAT_AREA] >= min_area:
            filtered_heatmap[labels == i] = 1
    return filtered_heatmap

def visualize_both_heatmaps(image: np.ndarray, original_heatmap: np.ndarray, 
                          filtered_heatmap: np.ndarray, target_size: Tuple[int, int]) -> None:
    """Visualize original and filtered heatmaps over grayscale image."""
    plt.figure(figsize=(20, 10))
    
    plt.subplot(1, 2, 1)
    plt.title("Original Heatmap")
    plt.imshow(cv2.resize(image[:, :, :3], target_size), cmap='gray')  # Use RGB channels
    plt.imshow(cv2.resize(original_heatmap, target_size), cmap='hot', alpha=0.5)
    plt.axis("off")
    
    plt.subplot(1, 2, 2)
    plt.title("Filtered Heatmap (Connected Components)")
    plt.imshow(cv2.resize(image[:, :, :3], target_size), cmap='gray')
    plt.imshow(cv2.resize(filtered_heatmap, target_size), cmap='hot', alpha=0.5)
    plt.axis("off")
    
    plt.show()

def save_heatmap(heatmap: np.ndarray, save_path: str, scale_factor: float) -> None:
    """Save heatmap as image."""
    new_size = (int(heatmap.shape[1] * scale_factor), int(heatmap.shape[0] * scale_factor))
    heatmap_resized = cv2.resize(heatmap, new_size)
    plt.imsave(save_path, heatmap_resized, cmap="hot")

def save_heatmap_overlay(image: np.ndarray, heatmap: np.ndarray, save_path: str, 
                        target_size: Tuple[int, int]) -> None:
    """Save heatmap overlay on RGB image."""
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.resize(image[:, :, :3], target_size), cmap='gray')
    plt.imshow(cv2.resize(heatmap, target_size), cmap='hot', alpha=0.8)
    plt.axis("off")
    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)
    plt.close()

def save_heatmap_bw(heatmap: np.ndarray, save_path: str, target_size: Tuple[int, int]) -> None:
    """Save black-and-white heatmap."""
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.resize(heatmap, target_size), cmap='gray')
    plt.axis("off")
    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)
    plt.close()

def save_white_overlay(image: np.ndarray, heatmap: np.ndarray, save_path: str, 
                     target_size: Tuple[int, int]) -> None:
    """Save white heatmap overlay (1→white, 0→black) on grayscale image."""
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.resize(image[:, :, :3], target_size), cmap='gray')
    plt.imshow(cv2.resize(heatmap, target_size), cmap='gray_r', alpha=0.5)
    plt.axis('off')
    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)
    plt.close()

def load_image(file_path: str) -> np.ndarray:
    """
    Load 4-channel image from .npy file.
    
    Args:
        file_path: Path to .npy file.
    
    Returns:
        4-channel image array.
    
    Raises:
        FileNotFoundError: If file cannot be loaded.
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Could not load image from {file_path}")
    return np.load(file_path)

def process_images(image_a_path: str, image_b_path: str, output_dir: str, 
                  config: Config, method: str) -> None:
    """Process image pair and generate heatmaps."""
    # Load images
    image_a = load_image(image_a_path)
    image_b = load_image(image_b_path)
    
    # Create patches
    patches_a = create_patches(image_a, config.patch_size)
    patches_b = create_patches(image_b, config.patch_size)
    
    # Build and process with U-Net
    input_shape = (config.patch_size, config.patch_size, 4)
    unet_model = build_unet(input_shape, config.channel_weights)
    embeddings_a = unet_model.predict(patches_a)
    embeddings_b = unet_model.predict(patches_b)
    
    # Generate heatmaps
    heatmaps = [
        generate_heatmap(
            np.abs(embeddings_a[i] - embeddings_b[i]),
            config.patch_size,
            config.threshold
        )
        for i in range(len(embeddings_a))
    ]
    
    # Stitch and filter heatmaps
    full_heatmap = stitch_heatmaps(heatmaps, image_a.shape[:2], config.patch_size)
    filtered_heatmap = apply_connected_components_filter(full_heatmap, config.min_area)
    
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Save results
    save_heatmap(full_heatmap, os.path.join(output_dir, f"{method}_heatmap.png"), config.scale_factor)
    save_heatmap(filtered_heatmap, os.path.join(output_dir, f"{method}_filtered_heatmap.png"), config.scale_factor)
    save_heatmap_overlay(image_a, full_heatmap, os.path.join(output_dir, f"{method}_heatmap_overlay.png"), config.target_size)
    save_heatmap_overlay(image_a, filtered_heatmap, os.path.join(output_dir, f"{method}_filtered_heatmap_overlay.png"), config.target_size)
    save_heatmap_bw(full_heatmap, os.path.join(output_dir, f"{method}_heatmap_bw.png"), config.target_size)
    save_heatmap_bw(filtered_heatmap, os.path.join(output_dir, f"{method}_filtered_heatmap_bw.png"), config.target_size)
    save_white_overlay(image_a, filtered_heatmap, os.path.join(output_dir, f"{method}_filtered_heatmap_white_overlay.png"), config.target_size)
    
    # Visualize results
    visualize_both_heatmaps(image_a, full_heatmap, filtered_heatmap, config.target_size)

def main():
    """Main function with command-line interface."""
    parser = argparse.ArgumentParser(description="Siamese U-Net for 4-Channel Image Difference Detection")
    parser.add_argument("--image_a", required=True, help="Path to first input image (.npy)")
    parser.add_argument("--image_b", required=True, help="Path to second input image (.npy)")
    parser.add_argument("--output_dir", required=True, help="Output directory for results")
    parser.add_argument("--method", choices=["kmean", "DBSCAN", "GMM", "AGG"], 
                       default="kmean", help="Clustering method")
    parser.add_argument("--patch_size", type=int, default=200, help="Patch size for processing")
    parser.add_argument("--threshold", type=float, default=0.06, help="Threshold for heatmap generation")
    parser.add_argument("--channel_weights", type=float, nargs=4, default=[1.0, 1.0, 1.0, 2.0],
                       help="Weights for R,G,B,K-means channels (default: 1,1,1,2)")
    
    args = parser.parse_args()
    
    # Initialize configuration
    config = Config(
        patch_size=args.patch_size,
        threshold=args.threshold,
        channel_weights=args.channel_weights
    )
    
    # Set up environment
    set_seed(config.seed)
    configure_gpu(config)
    
    # Process images
    process_images(args.image_a, args.image_b, args.output_dir, config, args.method)

if __name__ == "__main__":
    main()
